{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3873e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpipe-art==0.5.0 langchain-core tenacity datasets vllm faiss-cpu chromadb requests lxml numpy transformers torch gql==3.4.1 peft \n",
    "!pip install langchain-core tenacity datasets vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "965eaa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from secretsConfig import oaiKey, wandbKey, openRouterKey  # Add openRouterKey\n",
    "\n",
    "# Required for RULER judge model\n",
    "os.environ[\"OPENAI_API_KEY\"] = oaiKey\n",
    "\n",
    "# Required for Weights & Biases\n",
    "os.environ[\"WANDB_API_KEY\"] = wandbKey\n",
    "\n",
    "# Required for OpenRouter (Gemini judge)\n",
    "os.environ[\"OPENROUTER_API_KEY\"] = openRouterKey  # ADD THIS LINE\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"OPENAI_API_KEY is required for RULER functionality.\")\n",
    "\n",
    "if not os.environ.get(\"WANDB_API_KEY\"):\n",
    "    raise ValueError(\"WANDB_API_KEY is required for W&B.\")\n",
    "\n",
    "if not os.environ.get(\"OPENROUTER_API_KEY\"):\n",
    "    raise ValueError(\"OPENROUTER_API_KEY is required for Gemini judge.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f6c3f51",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'faiss'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrag_tools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msemantic_search\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAISSSemanticSearch\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrag_tools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeyword_search\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keyword_search\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrag_tools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mread_document\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m read_document_part\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/main_dir/Reply-AIM-Hackathon/rag_tools/semantic_search.py:14\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03msemantic_search.py - FAISS semantic search WITHOUT Ollama\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m \u001b[33;03mFor GPU support, use faiss-gpu instead of faiss-cpu\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfaiss\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01metree\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mElementTree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mET\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msqlite3\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'faiss'"
     ]
    }
   ],
   "source": [
    "from rag_tools.semantic_search import FAISSSemanticSearch\n",
    "from rag_tools.keyword_search import keyword_search\n",
    "from rag_tools.read_document import read_document_part\n",
    "\n",
    "# Wrap tools with error handling that tracks mistakes\n",
    "class ToolError:\n",
    "    \"\"\"Marker for tool execution errors\"\"\"\n",
    "    def __init__(self, message: str):\n",
    "        self.message = message\n",
    "\n",
    "_original_keyword_search = keyword_search\n",
    "_original_read_document_part = read_document_part\n",
    "\n",
    "def keyword_search_wrapped(query: str, num: int = 5) -> str:\n",
    "    \"\"\"Safe keyword search wrapper\"\"\"\n",
    "    try:\n",
    "        return _original_keyword_search(\"./data/normalized_enhanced.xml\", query, num)\n",
    "    except Exception as e:\n",
    "        error_msg = f\"[TOOL ERROR] keyword_search failed: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "\n",
    "def read_document_part_wrapped(part_id: str) -> str:\n",
    "    \"\"\"Safe read_document_part wrapper - validates part_id format\"\"\"\n",
    "    try:\n",
    "        if \" \" in part_id or len(part_id) > 100:\n",
    "            error_msg = f\"[INVALID PART_ID] '{part_id[:50]}...' is not a valid part_id format.\"\n",
    "            print(f\"[ERROR] Model tried to read invalid part_id: {part_id[:50]}...\")\n",
    "            return error_msg\n",
    "\n",
    "        return _original_read_document_part(\"./data/normalized_enhanced.xml\", part_id)\n",
    "    except Exception as e:\n",
    "        error_msg = f\"[TOOL ERROR] Failed to read document part: {str(e)}\"\n",
    "        print(f\"[ERROR] {error_msg}\")\n",
    "        return error_msg\n",
    "\n",
    "# Override with wrapped versions\n",
    "keyword_search = keyword_search_wrapped\n",
    "read_document_part = read_document_part_wrapped\n",
    "\n",
    "print(\"‚úÖ Tools wrapped with error handling and validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e659f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import random\n",
    "\n",
    "import art\n",
    "from art.serverless.backend import ServerlessBackend\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Declare the model - CHANGED TO QWEN3-14B\n",
    "model = art.TrainableModel(\n",
    "    name=\"legal-agent-001\",\n",
    "    project=\"legal-rag\",\n",
    "    base_model=\"Qwen/Qwen2.5-14B-Instruct\",  # Changed from Qwen2.5-14B-Instruct\n",
    ")\n",
    "\n",
    "# Initialize the server\n",
    "# Training and inference will run on Weights & Biases servers\n",
    "backend = ServerlessBackend()\n",
    "\n",
    "# Register the model with the Serverless Backend (sets up logging, inference, and training)\n",
    "await model.register(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9e83a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Rollout function defined!\n"
     ]
    }
   ],
   "source": [
    "from textwrap import dedent\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import AsyncOpenAI\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "import art\n",
    "\n",
    "MAX_TURNS = 4\n",
    "\n",
    "\n",
    "class FinalAnswer(BaseModel):\n",
    "    answer: str\n",
    "    source_ids: list[str]\n",
    "\n",
    "\n",
    "class LegalScenario(BaseModel):\n",
    "    id: str\n",
    "    question: str\n",
    "    gold_answer: str | None = None\n",
    "    gold_part_ids: list[str] | None = None\n",
    "\n",
    "\n",
    "class LegalScenarioStep(BaseModel):\n",
    "    step: int\n",
    "    scenario: LegalScenario\n",
    "\n",
    "\n",
    "async def rollout(model: art.Model, legal_scenario_step: LegalScenarioStep) -> art.Trajectory:\n",
    "    \"\"\"Execute one trajectory rollout\"\"\"\n",
    "    scenario = legal_scenario_step.scenario\n",
    "    \n",
    "    traj = art.Trajectory(\n",
    "        reward=0.0,\n",
    "        messages_and_choices=[],\n",
    "        metadata={\"scenario_id\": scenario.id, \"step\": legal_scenario_step.step},\n",
    "    )\n",
    "\n",
    "    # YOUR CUSTOM PROMPT HERE\n",
    "    system_prompt = dedent(\n",
    "        f\"\"\"\n",
    "        You are a legal research assistant that can search legal documents to answer questions.\n",
    "\n",
    "        You have access to the following tools:\n",
    "\n",
    "        - search_keyword(query: str, num: int) -> str: Search using keyword/BM25 search for exact term matches.\n",
    "        - search_semantic(query: str, num: int) -> str: Search using semantic/vector search for conceptual similarity.\n",
    "        - read_document_part(part_id: str) -> str: Read a document part by ID. Part IDs use hierarchical format (e.g., A:B:C). To access parent parts, remove the last segment (e.g., A:B:C ‚Üí parent is A:B).\n",
    "\n",
    "        You may call one tool per turn, for up to {MAX_TURNS} turns, before giving your final answer.\n",
    "\n",
    "        In each turn, you should analyze what information you need and respond with EITHER a tool call OR your final answer.\n",
    "\n",
    "        For tool calls, use this format:\n",
    "        <think>\n",
    "        [your reasoning for what to search for and why]\n",
    "        </think>\n",
    "        <tool>\n",
    "        {{\"name\": \"tool_name\", \"args\": {{\"query\": \"search query\"}}}}\n",
    "        </tool>\n",
    "\n",
    "        When you have enough information, give your final answer in this format:\n",
    "\n",
    "        <think>\n",
    "        [your reasoning for the answer]\n",
    "        </think>\n",
    "        <answer>\n",
    "        [your comprehensive answer citing the evidence you found or \"I don't know\" if you didn't get enough information]\n",
    "\n",
    "        <sources>\n",
    "        <source>doc_id_1</source>\n",
    "        </sources>\n",
    "        </answer>\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    traj.messages_and_choices = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": scenario.question},\n",
    "    ]\n",
    "\n",
    "    # Define tools\n",
    "    def search_keyword_tool(query: str, num: int = 5) -> str:\n",
    "        return keyword_search(query, num)\n",
    "\n",
    "    def search_semantic_tool(query: str, num: int = 5) -> str:\n",
    "        searcher = FAISSSemanticSearch()\n",
    "        return searcher.search(query, num)\n",
    "\n",
    "    def read_document_part_tool(part_id: str) -> str:\n",
    "        return read_document_part(part_id)\n",
    "\n",
    "    def return_final_answer(answer: str, source_ids: list[str]) -> FinalAnswer:\n",
    "        return FinalAnswer(answer=answer, source_ids=source_ids)\n",
    "\n",
    "    tools = [search_keyword_tool, search_semantic_tool, read_document_part_tool, return_final_answer]\n",
    "    tools_by_name = {t.__name__: t for t in tools}\n",
    "    traj.tools = [convert_to_openai_tool(t) for t in tools]\n",
    "\n",
    "    client = AsyncOpenAI(\n",
    "        base_url=model.inference_base_url,\n",
    "        api_key=model.inference_api_key,\n",
    "    )\n",
    "\n",
    "    for _ in range(MAX_TURNS):\n",
    "        response = await client.chat.completions.create(\n",
    "            model=model.get_inference_name(),\n",
    "            temperature=1,\n",
    "            messages=traj.messages(),\n",
    "            tools=traj.tools,\n",
    "        )\n",
    "\n",
    "        response_message = response.choices[0].message\n",
    "        traj.messages_and_choices.append(response.choices[0])\n",
    "\n",
    "        if not response_message.tool_calls:\n",
    "            return traj\n",
    "\n",
    "        try:\n",
    "            for tool_call in response_message.tool_calls:\n",
    "                tool_name = tool_call.function.name\n",
    "                if tool_name in tools_by_name:\n",
    "                    tool_args = json.loads(tool_call.function.arguments)\n",
    "                    result = tools_by_name[tool_name](**tool_args)\n",
    "                    traj.messages_and_choices.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"name\": tool_name,\n",
    "                        \"content\": str(result),\n",
    "                    })\n",
    "\n",
    "                    if tool_name == \"return_final_answer\":\n",
    "                        return traj\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return traj\n",
    "\n",
    "    return traj\n",
    "\n",
    "\n",
    "print(\"‚úÖ Rollout function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f5c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from litellm import acompletion\n",
    "\n",
    "# Load your training data\n",
    "DATA_FILE = \"./data/snippet_data.json\"\n",
    "\n",
    "print(f\"Loading data from {DATA_FILE}...\")\n",
    "with open(DATA_FILE, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert to LegalScenario objects\n",
    "training_scenarios = []\n",
    "for item in data.get(\"items\", []):\n",
    "    for row in item.get(\"rows\", []):\n",
    "        sources = row.get(\"sources\", [])\n",
    "        gold_part_ids = sources if sources else []\n",
    "        \n",
    "        training_scenarios.append(\n",
    "            LegalScenario(\n",
    "                id=str(row[\"row_index\"]),\n",
    "                question=row[\"question\"],\n",
    "                gold_answer=row.get(\"model_answer\", \"\"),\n",
    "                gold_part_ids=gold_part_ids\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(training_scenarios)} scenarios\")\n",
    "\n",
    "\n",
    "# Custom RULER function using OpenRouter with detailed reward criteria\n",
    "async def gemini_ruler_score_group(group: art.TrajectoryGroup) -> art.TrajectoryGroup:\n",
    "      \"\"\"\n",
    "      Score trajectories using Gemini 2.5 Flash via OpenRouter\n",
    "\n",
    "      NEW SCORING CRITERIA:\n",
    "      - Correct answer: 1.0 to 2.0 points\n",
    "      - \"I don't know\" (appropriate): 0.0 to 1.0 points\n",
    "      - Wrong answer (hallucination): -1.0 to 0.0 points\n",
    "      - Format errors (tool misuse): -2.0 to -1.0 points\n",
    "\n",
    "      Bonuses:\n",
    "      - Fewer turns: +0.1 to +0.2\n",
    "      - Fewer searches: +0.1\n",
    "\n",
    "      Key: \"I don't know\" > wrong answer (penalizes hallucination)\n",
    "      \"\"\"\n",
    "\n",
    "      trajectories = group.trajectories\n",
    "      if len(trajectories) <= 1:\n",
    "          for traj in trajectories:\n",
    "              traj.reward = 0.0\n",
    "          return group\n",
    "\n",
    "      # Analyze each trajectory for tool usage and format errors\n",
    "      trajectory_analyses = []\n",
    "      for i, traj in enumerate(trajectories):\n",
    "          messages = traj.messages()\n",
    "          final_answer = messages[-1].get(\"content\", \"\") if messages else \"\"\n",
    "\n",
    "          # Analyze tool usage\n",
    "          format_errors = []\n",
    "          num_searches = 0\n",
    "          num_turns = 0\n",
    "\n",
    "          for msg in messages:\n",
    "              if isinstance(msg, dict):\n",
    "                  if msg.get(\"role\") == \"assistant\":\n",
    "                      num_turns += 1\n",
    "\n",
    "                  if msg.get(\"role\") == \"tool\":\n",
    "                      tool_name = msg.get(\"name\", \"\")\n",
    "                      content = msg.get(\"content\", \"\")\n",
    "\n",
    "                      if \"search\" in tool_name.lower():\n",
    "                          num_searches += 1\n",
    "\n",
    "                      # Detect format errors\n",
    "                      if \"[TOOL ERROR]\" in content or \"[INVALID PART_ID]\" in content or \"[PART NOT FOUND]\" in content:\n",
    "                          format_errors.append(content[:80])\n",
    "\n",
    "          trajectory_analyses.append({\n",
    "              \"index\": i,\n",
    "              \"final_answer\": final_answer[:400],\n",
    "              \"num_turns\": num_turns,\n",
    "              \"num_searches\": num_searches,\n",
    "              \"has_format_error\": len(format_errors) > 0,\n",
    "              \"format_errors\": format_errors\n",
    "          })\n",
    "\n",
    "      # Build prompt for Gemini judge\n",
    "      analysis_text = \"\"\n",
    "      for analysis in trajectory_analyses:\n",
    "          analysis_text += f\"\"\"\n",
    "  **Response {analysis['index'] + 1}:**\n",
    "  - Answer: {analysis['final_answer']}\n",
    "  - Turns: {analysis['num_turns']}/{MAX_TURNS}\n",
    "  - Searches: {analysis['num_searches']}\n",
    "  - Format Errors: {\"YES\" if analysis['has_format_error'] else \"NO\"}\n",
    "  \"\"\"\n",
    "\n",
    "      judge_prompt = f\"\"\"Evaluate these {len(trajectories)} legal\n",
    "  research responses.\n",
    "\n",
    "  SCORING RULES:\n",
    "  1. Correct answer with citations: 1.0 to 2.0 points\n",
    "  2. \"I don't know\" when uncertain (GOOD - avoids hallucination): 0.0\n",
    "  to 1.0 points\n",
    "  3. Wrong/hallucinated answer: -1.0 to 0.0 points\n",
    "  4. Format errors (tool misuse): -2.0 to -1.0 points\n",
    "\n",
    "  CRITICAL: \"I don't know\" is BETTER than wrong answer. Penalize\n",
    "  hallucination heavily.\n",
    "\n",
    "  Responses:\n",
    "  {analysis_text}\n",
    "\n",
    "  Return JSON:\n",
    "  {{\n",
    "    \"scores\": [\n",
    "      {{\"base_score\": 1.5, \"reasoning\": \"why\"}},\n",
    "      {{\"base_score\": 0.5, \"reasoning\": \"why\"}},\n",
    "      {{\"base_score\": -0.5, \"reasoning\": \"why\"}}\n",
    "    ]\n",
    "  }}\n",
    "\n",
    "  Evaluation:\"\"\"\n",
    "\n",
    "      try:\n",
    "          # Call Gemini\n",
    "          response = await acompletion(\n",
    "              model=\"openrouter/google/gemini-2.5-flash\",\n",
    "              messages=[{\"role\": \"user\", \"content\": judge_prompt}],\n",
    "              api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
    "              max_tokens=500,\n",
    "          )\n",
    "\n",
    "          result_text = response.choices[0].message.content.strip()\n",
    "\n",
    "          # Parse JSON\n",
    "          import re\n",
    "          json_match = re.search(r'\\{[\\s\\S]*\\}', result_text)\n",
    "          if json_match:\n",
    "              result = json.loads(json_match.group())\n",
    "              base_scores = [item[\"base_score\"] for item in result[\"scores\"]]\n",
    "          else:\n",
    "              # Fallback: simple array\n",
    "              json_match = re.search(r'\\[[\\d\\.,\\s-]+\\]', result_text)\n",
    "              base_scores = json.loads(json_match.group()) if json_match else [0.0] * len(trajectories)\n",
    "\n",
    "          # Apply efficiency bonuses\n",
    "          final_scores = []\n",
    "          for base_score, analysis in zip(base_scores, trajectory_analyses):\n",
    "              score = float(base_score)\n",
    "\n",
    "              # Only give bonuses if no format errors\n",
    "              if not analysis['has_format_error']:\n",
    "                  # Fewer turns bonus\n",
    "                  turn_efficiency = (MAX_TURNS - analysis['num_turns']) / MAX_TURNS\n",
    "                  score += turn_efficiency * 0.2  # Up to +0.2\n",
    "\n",
    "                  # Fewer searches bonus\n",
    "                  if analysis['num_searches'] <= 2:\n",
    "                      score += 0.1\n",
    "\n",
    "              final_scores.append(round(score, 2))\n",
    "\n",
    "          # Assign scores\n",
    "          for traj, score in zip(trajectories, final_scores):\n",
    "              traj.reward = float(score)\n",
    "\n",
    "          print(f\"  Base: {[f'{s:.2f}' for s in base_scores]} ‚Üí Final: {[f'{s:.2f}' for s in final_scores]}\")\n",
    "\n",
    "      except Exception as e:\n",
    "          print(f\"  Judge error: {e}\")\n",
    "          # Fallback: penalize format errors\n",
    "          for traj, analysis in zip(trajectories, trajectory_analyses):\n",
    "              traj.reward = -1.5 if analysis['has_format_error'] else 0.5\n",
    "\n",
    "      return group\n",
    "\n",
    "\n",
    "# Test the NEW judge\n",
    "print(\"\\nüß™ Testing NEW scoring criteria...\")\n",
    "\n",
    "test_scenario = training_scenarios[0]\n",
    "base_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a legal research agent.\"},\n",
    "    {\"role\": \"user\", \"content\": test_scenario.question},\n",
    "]\n",
    "\n",
    "# Test case 1: Good answer\n",
    "good_traj = art.Trajectory(\n",
    "    messages_and_choices=[\n",
    "        *base_messages,\n",
    "        {\"role\": \"assistant\", \"content\": test_scenario.gold_answer},\n",
    "    ],\n",
    "    reward=0,\n",
    ")\n",
    "\n",
    "# Test case 2: \"I don't know\" (should score higher than wrong answer)\n",
    "idk_traj = art.Trajectory(\n",
    "    messages_and_choices=[\n",
    "        *base_messages,\n",
    "        {\"role\": \"assistant\", \"content\": \"I don't know - I couldn't find sufficient information to answer confidently.\"},\n",
    "    ],\n",
    "    reward=0,\n",
    ")\n",
    "\n",
    "# Test case 3: Hallucinated wrong answer (should score lowest)\n",
    "wrong_traj = art.Trajectory(\n",
    "    messages_and_choices=[\n",
    "        *base_messages,\n",
    "        {\"role\": \"assistant\", \"content\": \"The Supreme Court ruled that all contracts are void under maritime law based on Article 5.\"},\n",
    "    ],\n",
    "    reward=0,\n",
    ")\n",
    "\n",
    "test_group = art.TrajectoryGroup(trajectories=[good_traj, idk_traj, wrong_traj])\n",
    "judged_group = await gemini_ruler_score_group(test_group)\n",
    "\n",
    "# Display results\n",
    "sorted_trajs = sorted(judged_group.trajectories, key=lambda t: t.reward, reverse=True)\n",
    "print(\"\\nüìä Ranking:\")\n",
    "for rank, traj in enumerate(sorted_trajs, 1):\n",
    "    msgs = traj.messages()\n",
    "    print(f\"  {rank}. Score {traj.reward:.2f} - {msgs[-1]['content'][:60]}...\")\n",
    "\n",
    "print(\"\\n‚úÖ New scoring criteria working! ('I don't know' should rank above wrong answer)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e719f56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshng2025\u001b[0m (\u001b[33mImperial-College-London-SPQR\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/maindir/wandb/run-20251012_003057-6q6qwhwv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025/runs/6q6qwhwv' target=\"_blank\">honest-plasma-9</a></strong> to <a href='https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025' target=\"_blank\">https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025/runs/6q6qwhwv' target=\"_blank\">https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025/runs/6q6qwhwv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [litellm, openai] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Weave is installed but not imported. Add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting training loop...\n",
      "\n",
      "üíª Model inference running on: W&B Serverless (not your A100s)\n",
      "üìä W&B Dashboard: https://wandb.ai/Imperial-College-London-SPQR/IBM-Datathon-Z-2025/runs/6q6qwhwv\n",
      "üè∑Ô∏è  Run name: honest-plasma-9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating dataset:   0%|          | 0/150 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 0 | Epoch 0 | Epoch Step 0 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  5.55it/s, reward=0, completion_tokens=83.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.5, 1.5, 1.5, 1.5, 1.5, 0.5]\n",
      "  Scores: [0.5, 1.0, 1.5, 0.0, 1.0, 1.0]\n",
      "  Rewards: avg=1.083, max=1.500, min=0.000\n",
      "  Correct: 9, IDK: 3, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.33s/it, entropy=0.352, grad_norm=0.659, loss=0.361, policy_loss=0.361]\n",
      "Iterating dataset:   1%|          | 1/150 [00:24<1:01:18, 24.69s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 0 complete\n",
      "\n",
      "=== Step 1 | Epoch 0 | Epoch Step 1 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:04<00:00,  2.32it/s, exceptions=2, reward=0, completion_tokens=84.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [1.0, 1.0, 1.5, 1.5, 2.0, 1.0]\n",
      "  Scores: [1.5, 1.8, 2.0, 1.0]\n",
      "  Rewards: avg=1.430, max=2.000, min=1.000\n",
      "  Correct: 10, IDK: 0, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:17<00:00,  8.64s/it, entropy=0.263, grad_norm=0.194, loss=-0.153, policy_loss=-0.153]\n",
      "Iterating dataset:   1%|‚ñè         | 2/150 [00:55<1:10:08, 28.44s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Step 1 complete\n",
      "\n",
      "=== Step 2 | Epoch 0 | Epoch Step 2 ===\n",
      "Batch: 2 scenarios\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gathering trajectories:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:03<00:00,  2.68it/s, exceptions=2, reward=0, completion_tokens=58.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Scores: [0.5, 2.0, 0.0, 0.5]\n",
      "  Scores: [0.5, 0.8, 1.2, 1.0, 1.5, 1.8]\n",
      "  Rewards: avg=0.980, max=2.000, min=0.000\n",
      "  Correct: 5, IDK: 5, Wrong: 0, Format Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from art.utils import iterate_dataset\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize W&B with auto-generated run name\n",
    "wandb.login(key=os.environ[\"WANDB_API_KEY\"])\n",
    "run = wandb.init(\n",
    "    project=\"IBM-Datathon-Z-2025\",\n",
    "    config={\n",
    "        \"model\": \"Qwen/Qwen2.5-14B-Instruct\",\n",
    "        \"groups_per_step\": 2,\n",
    "        \"num_epochs\": 3,\n",
    "        \"rollouts_per_group\": 6,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"max_steps\": 50,\n",
    "        \"max_turns\": MAX_TURNS,\n",
    "    },\n",
    "    # Remove the name parameter to get auto-generated names with numbers\n",
    "    # name=\"legal-rag-rl-training\"  # REMOVED THIS LINE\n",
    ")\n",
    "\n",
    "# Training config\n",
    "training_config = run.config\n",
    "\n",
    "# Create training iterator starting from step 0 (fresh run)\n",
    "training_iterator = iterate_dataset(\n",
    "    training_scenarios,\n",
    "    groups_per_step=training_config[\"groups_per_step\"],\n",
    "    num_epochs=training_config[\"num_epochs\"],\n",
    "    initial_step=0,  # CHANGED: Always start from 0 for fresh runs\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting training loop...\\n\")\n",
    "print(f\"üíª Model inference running on: W&B Serverless (not your A100s)\")\n",
    "print(f\"üìä W&B Dashboard: {run.url}\")\n",
    "print(f\"üè∑Ô∏è  Run name: {run.name}\\n\")\n",
    "\n",
    "step_count = 0\n",
    "\n",
    "for batch in training_iterator:\n",
    "    print(f\"=== Step {batch.step} | Epoch {batch.epoch} | Epoch Step {batch.epoch_step} ===\")\n",
    "    print(f\"Batch: {len(batch.items)} scenarios\")\n",
    "    \n",
    "    # Create trajectory groups\n",
    "    groups = []\n",
    "    for scenario in batch.items:\n",
    "        groups.append(\n",
    "            art.TrajectoryGroup(\n",
    "                (\n",
    "                    rollout(model, LegalScenarioStep(step=batch.step, scenario=scenario))\n",
    "                    for _ in range(training_config[\"rollouts_per_group\"])\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Gather trajectories\n",
    "    finished_groups = await art.gather_trajectory_groups(\n",
    "        groups,\n",
    "        pbar_desc=\"Gathering trajectories\",\n",
    "        max_exceptions=training_config[\"rollouts_per_group\"] * len(batch.items),\n",
    "    )\n",
    "    \n",
    "    # Judge with custom Gemini function\n",
    "    judged_groups = []\n",
    "    for group in finished_groups:\n",
    "        judged_group = await gemini_ruler_score_group(group)\n",
    "        judged_groups.append(judged_group)\n",
    "    \n",
    "    # Calculate metrics before training\n",
    "    all_rewards = [t.reward for g in judged_groups for t in g.trajectories]\n",
    "    avg_reward = sum(all_rewards) / len(all_rewards)\n",
    "    max_reward = max(all_rewards)\n",
    "    min_reward = min(all_rewards)\n",
    "    \n",
    "    # Count trajectories by reward band\n",
    "    correct_count = sum(1 for r in all_rewards if r >= 1.0)\n",
    "    idk_count = sum(1 for r in all_rewards if 0.0 <= r < 1.0)\n",
    "    wrong_count = sum(1 for r in all_rewards if -1.0 <= r < 0.0)\n",
    "    format_error_count = sum(1 for r in all_rewards if r < -1.0)\n",
    "    \n",
    "    # Log to W&B\n",
    "    wandb.log({\n",
    "        \"step\": step_count,  # Use step_count instead of batch.step\n",
    "        \"epoch\": batch.epoch,\n",
    "        \"avg_reward\": avg_reward,\n",
    "        \"max_reward\": max_reward,\n",
    "        \"min_reward\": min_reward,\n",
    "        \"correct_count\": correct_count,\n",
    "        \"idk_count\": idk_count,\n",
    "        \"wrong_count\": wrong_count,\n",
    "        \"format_error_count\": format_error_count,\n",
    "        \"total_trajectories\": len(all_rewards),\n",
    "    })\n",
    "    \n",
    "    print(f\"  Rewards: avg={avg_reward:.3f}, max={max_reward:.3f}, min={min_reward:.3f}\")\n",
    "    print(f\"  Correct: {correct_count}, IDK: {idk_count}, Wrong: {wrong_count}, Format Errors: {format_error_count}\")\n",
    "    \n",
    "    # Train on judged trajectories\n",
    "    await model.delete_checkpoints()\n",
    "    await model.train(\n",
    "        judged_groups,\n",
    "        config=art.TrainConfig(learning_rate=training_config[\"learning_rate\"]),\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Step {step_count} complete\\n\")\n",
    "    \n",
    "    step_count += 1\n",
    "    \n",
    "    # Stop after max_steps\n",
    "    if step_count >= training_config[\"max_steps\"]:\n",
    "        break\n",
    "\n",
    "run.finish()\n",
    "print(\"üéâ Training complete!\")\n",
    "print(f\"üìä View results: {run.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b06c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
